{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c21547d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11b1c1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (19588, 2)\n",
      "                                                text  label\n",
      "0  Subject: enron methanol ; meter # : 988291\\r\\n...      0\n",
      "1  Subject: hpl nom for january 9 , 2001\\r\\n( see...      0\n",
      "2  Subject: neon retreat\\r\\nho ho ho , we ' re ar...      0\n",
      "3  Subject: photoshop , windows , office . cheap ...      1\n",
      "4  Subject: re : indian springs\\r\\nthis deal is t...      0\n",
      "\n",
      "Columns: Index(['text', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"F:\\\\Projects_spam_email_ML&URL_models\\\\Data\\\\SpamEmail_data\\\\final_merged_spam_dataset.csv\")\n",
    "\n",
    "print(\"Shape of dataset:\", data.shape)\n",
    "print(data.head())\n",
    "print(\"\\nColumns:\", data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88b134e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      " text     0\n",
      "label    0\n",
      "dtype: int64\n",
      "\n",
      "Shape after cleaning: (18893, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in each column:\\n\", data.isnull().sum())\n",
    "\n",
    "data = data.dropna(subset=['text'])\n",
    "data = data.drop_duplicates(subset=['text'])\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print(\"\\nShape after cleaning:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d9dd496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Percentage distribution:\n",
      "label\n",
      "0    73.593394\n",
      "1    26.406606\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPercentage distribution:\")\n",
    "print(data['label'].value_counts(normalize=True) * 100)  # covert value count to proportions and *100-->convert into percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f6aa77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Step 7: Text Preprocessing Pipeline\n",
    "Includes:\n",
    "1. Cleaning\n",
    "2. Tokenization\n",
    "3. Stopword removal\n",
    "4. POS-based lemmatization\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "df = data.copy()\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = re.sub(r'\\r\\n|\\n|\\r', ' ', text)\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', ' url ', text)\n",
    "    text = re.sub(r'\\S+@\\S+', ' email ', text)\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    text = re.sub(r'\\d+', ' ', text)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', ' ', text)\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "df['clean_text'] = df['text'].astype(str).apply(clean_text)\n",
    "\n",
    "\n",
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "def tokenize_remove_stopwords(text):\n",
    "    tokens = text.split()\n",
    "    return [t for t in tokens if t not in STOP_WORDS and len(t) > 1]\n",
    "\n",
    "df['tokens'] = df['clean_text'].apply(tokenize_remove_stopwords)\n",
    "\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def map_pos_tag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_words(tokens):\n",
    "    if not tokens:\n",
    "        return []\n",
    "    tagged_tokens = pos_tag(tokens)\n",
    "    return [lemmatizer.lemmatize(word, map_pos_tag(tag)) \n",
    "            for word, tag in tagged_tokens]\n",
    "\n",
    "df['lemmatized_tokens'] = df['tokens'].apply(lemmatize_words)\n",
    "\n",
    "df['text_lemmatized'] = df['lemmatized_tokens'] \\\n",
    "                          .apply(lambda x: \" \".join(x))\n",
    "\n",
    "\n",
    "required_columns = [\n",
    "    col for col in \n",
    "    ['ID', 'label', 'label_num', 'clean_text', 'text_lemmatized']\n",
    "    if col in df.columns\n",
    "]\n",
    "\n",
    "data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f01371de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 13225\n",
      "Testing samples : 5668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['text_lemmatized'],   \n",
    "    data['label'],            \n",
    "    test_size=0.30,           \n",
    "    stratify=data['label'],  # preserve class distribution  \n",
    "    random_state=42           \n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Testing samples : {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "722bc1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vector shape: (13225, 20000)\n",
      "Testing vector shape : (5668, 20000)\n",
      "Vocabulary size      : 20000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=20000,     \n",
    "    ngram_range=(1, 2),     \n",
    "    min_df=3,              \n",
    "    stop_words=None       \n",
    ")\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(\n",
    "    X_train.astype(str)\n",
    ")\n",
    "\n",
    "X_test_tfidf = tfidf_vectorizer.transform(\n",
    "    X_test.astype(str)\n",
    ")\n",
    "\n",
    "print(\"Training vector shape:\", X_train_tfidf.shape)\n",
    "print(\"Testing vector shape :\", X_test_tfidf.shape)\n",
    "print(\"Vocabulary size      :\", len(tfidf_vectorizer.vocabulary_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e524914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best hyperparameters:\n",
      "{'C': 2, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "\n",
    "svm_model = LinearSVC(\n",
    "    max_iter=10000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"C\": [0.1, 0.5, 1, 2, 5, 10],\n",
    "    \"class_weight\": [None, \"balanced\"]\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=svm_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring=\"f1\",   \n",
    "    cv=cv_strategy,\n",
    "    n_jobs=-1,   # Use all CPU cores          \n",
    "    verbose=2,\n",
    "    refit=True   # retrain best model on full train data          \n",
    ")\n",
    "\n",
    "grid_search.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Best tuned model\n",
    "best_svm_tfidf = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb1908d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance: TF-IDF + Linear SVM --\n",
      "\n",
      "Accuracy  : 0.9903\n",
      "Precision : 0.9756\n",
      "Recall    : 0.9880\n",
      "F1-score  : 0.9817\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4134   37]\n",
      " [  18 1479]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9957    0.9911    0.9934      4171\n",
      "           1     0.9756    0.9880    0.9817      1497\n",
      "\n",
      "    accuracy                         0.9903      5668\n",
      "   macro avg     0.9856    0.9896    0.9876      5668\n",
      "weighted avg     0.9904    0.9903    0.9903      5668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "y_test_pred = best_svm_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"Test Performance: TF-IDF + Linear SVM --\\n\")\n",
    "accuracy  = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "recall    = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "f1        = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy  : {accuracy:.4f}\")\n",
    "print(f\"Precision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1-score  : {f1:.4f}\")\n",
    "\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(cm)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_test_pred,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d08ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability Calibration for SVM\n",
    "\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "\n",
    "svm_calibrated = CalibratedClassifierCV(\n",
    "    estimator=best_svm_tfidf,\n",
    "    cv=5)  \n",
    "           \n",
    "svm_calibrated.fit(X_train_tfidf, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942a1c3",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "556351e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "\n",
      "Best hyperparameters:\n",
      "{'alpha': 0.1}\n",
      "Best CV score: 0.9640\n",
      "\n",
      " Test Performance: TF-IDF + Naive Bayes: \n",
      "Accuracy  : 0.9820\n",
      "Precision : 0.9722\n",
      "Recall    : 0.9593\n",
      "F1-score  : 0.9657\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4130   41]\n",
      " [  61 1436]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9854    0.9902    0.9878      4171\n",
      "           1     0.9722    0.9593    0.9657      1497\n",
      "\n",
      "    accuracy                         0.9820      5668\n",
      "   macro avg     0.9788    0.9747    0.9768      5668\n",
      "weighted avg     0.9820    0.9820    0.9820      5668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "\n",
    "param_grid_nb = {\n",
    "    \"alpha\": [0.1, 0.3, 0.5, 1.0, 2.0, 5.0]\n",
    "}\n",
    "\n",
    "cv_strategy_nb = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_nb = GridSearchCV(\n",
    "    estimator=nb_model,\n",
    "    param_grid=param_grid_nb,\n",
    "    scoring=\"f1\",     # can change to \"f1\"\n",
    "    cv=cv_strategy_nb,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    refit=True\n",
    ")\n",
    "\n",
    "grid_search_nb.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(\"\\nBest hyperparameters:\")\n",
    "print(grid_search_nb.best_params_)\n",
    "\n",
    "print(f\"Best CV score: {grid_search_nb.best_score_:.4f}\")\n",
    "\n",
    "best_nb_model = grid_search_nb.best_estimator_\n",
    "\n",
    "y_test_pred_nb = best_nb_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\n Test Performance: TF-IDF + Naive Bayes: \")\n",
    "\n",
    "accuracy  = accuracy_score(y_test, y_test_pred_nb)\n",
    "precision = precision_score(y_test, y_test_pred_nb, zero_division=0)\n",
    "recall    = recall_score(y_test, y_test_pred_nb, zero_division=0)\n",
    "f1        = f1_score(y_test, y_test_pred_nb, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy  : {accuracy:.4f}\")\n",
    "print(f\"Precision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1-score  : {f1:.4f}\")\n",
    "\n",
    "cm = confusion_matrix(y_test, y_test_pred_nb)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_test_pred_nb,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f220ad68",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16c8b6b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scale_pos_weight = 2.7872279495990835\n",
      "\n",
      " Test Performance: TF-IDF + XGBoost: \n",
      "\n",
      "Confusion Matrix:\n",
      "[[4063  108]\n",
      " [  17 1480]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9958    0.9741    0.9849      4171\n",
      "           1     0.9320    0.9886    0.9595      1497\n",
      "\n",
      "    accuracy                         0.9779      5668\n",
      "   macro avg     0.9639    0.9814    0.9722      5668\n",
      "weighted avg     0.9790    0.9779    0.9782      5668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Handling class imbalance\n",
    "ham_count  = (y_train == 0).sum()\n",
    "spam_count = (y_train == 1).sum()\n",
    "scale_pos_weight = ham_count / spam_count\n",
    "print(\"scale_pos_weight =\", scale_pos_weight)\n",
    "\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    n_estimators=300,\n",
    "    max_depth=5,\n",
    "    learning_rate=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    eval_metric=\"logloss\"\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "y_test_pred_xgb = xgb_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\n Test Performance: TF-IDF + XGBoost: \")\n",
    "\n",
    "accuracy  = accuracy_score(y_test, y_test_pred_xgb)\n",
    "precision = precision_score(y_test, y_test_pred_xgb, zero_division=0)\n",
    "recall    = recall_score(y_test, y_test_pred_xgb, zero_division=0)\n",
    "f1        = f1_score(y_test, y_test_pred_xgb, zero_division=0)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred_xgb))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_test_pred_xgb,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a93365",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2da6130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==============================\n",
      " Model: K-Fold Stacking (SVM + NB + XGB → LR)\n",
      "==============================\n",
      "Accuracy : 0.9917\n",
      "Precision: 0.9814\n",
      "Recall   : 0.9873\n",
      "F1-score : 0.9843\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4143   28]\n",
      " [  19 1478]]\n",
      "\n",
      "Binary Interpretation:\n",
      "TP (spam → spam): 1478\n",
      "TN (ham  → ham) : 4143\n",
      "FP (ham  → spam): 28\n",
      "FN (spam → ham): 19\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9954    0.9933    0.9944      4171\n",
      "           1     0.9814    0.9873    0.9843      1497\n",
      "\n",
      "    accuracy                         0.9917      5668\n",
      "   macro avg     0.9884    0.9903    0.9894      5668\n",
      "weighted avg     0.9917    0.9917    0.9917      5668\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# meta learner\n",
    "meta_model = LogisticRegression(max_iter=3000)\n",
    "\n",
    "stack_cv = StratifiedKFold(\n",
    "    n_splits=5,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[\n",
    "        (\"svm\", svm_calibrated),\n",
    "        (\"nb\",  best_nb_model),\n",
    "        (\"xgb\", xgb_model)\n",
    "    ],\n",
    "    final_estimator=meta_model,\n",
    "    stack_method=\"auto\",\n",
    "    cv=stack_cv,          # enables K-Fold stacking\n",
    "    n_jobs=-1\n",
    ")\n",
    "stacking_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n",
    "y_pred_stack = stacking_model.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\n Test Performance: K-Fold Stacking (SVM + NB + XGB → LR): \")\n",
    "\n",
    "accuracy  = accuracy_score(y_test, y_pred_stack)\n",
    "precision = precision_score(y_test, y_pred_stack, zero_division=0)\n",
    "recall    = recall_score(y_test, y_pred_stack, zero_division=0)\n",
    "f1        = f1_score(y_test, y_pred_stack, zero_division=0)\n",
    "\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_stack)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred_stack,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    "))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa4a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2cd2946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train F1: 0.9979977116704806\n",
      "Test  F1: 0.9843489843489843\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train vs Test F1-Score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Predict on TRAIN\n",
    "y_train_pred = stacking_model.predict(X_train_tfidf)\n",
    "\n",
    "# Predict on TEST\n",
    "y_test_pred  = stacking_model.predict(X_test_tfidf)\n",
    "\n",
    "# Compute F1 scores\n",
    "train_f1 = f1_score(y_train, y_train_pred)\n",
    "test_f1  = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(\"Train F1:\", train_f1)\n",
    "print(\"Test  F1:\", test_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7842dbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
